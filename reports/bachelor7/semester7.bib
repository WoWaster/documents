@article{akkadEmbeddedDeepLearning2024,
  title = {Embedded {{Deep Learning Accelerators}}: {{A Survey}} on {{Recent Advances}}},
  shorttitle = {Embedded {{Deep Learning Accelerators}}},
  author = {Akkad, Ghattas and Mansour, Ali and Inaty, Elie},
  date = {2024-05},
  journaltitle = {IEEE Transactions on Artificial Intelligence},
  volume = {5},
  number = {5},
  pages = {1954--1972},
  issn = {2691-4581},
  doi = {10.1109/TAI.2023.3311776},
  url = {https://ieeexplore.ieee.org/document/10239336/?arnumber=10239336},
  urldate = {2025-02-22},
  abstract = {The exponential increase in generated data as well as the advances in high-performance computing has paved the way for the use of complex machine learning methods. Indeed, the availability of graphical processing units and tensor processing units has made it possible to train and prototype deep neural networks (DNNs) on large-scale datasets and for a variety of applications, i.e., vision, robotics, biomedical, etc. The popularity of these DNNs originates from their efficacy and state-of-the-art inference accuracy. However, this is obtained at the cost of a considerably high computational complexity. Such drawbacks rendered their implementation on limited resources, edge devices, without a major loss in inference speed and accuracy, a dire and challenging task. To this extent, it has become extremely important to design innovative architectures and dedicated accelerators to deploy these DNNs to embedded and reconfigurable processors in a high-performance low-complexity structure. In this study, we present a survey on recent advances in deep learning accelerators for heterogeneous systems and Reduced Instruction Set Computer processors given their open-source nature, accessibility, customizability, and universality. After reading this article, the readers should have a comprehensive overview of the recent progress in this domain, cutting edge knowledge of recent embedded machine learning trends, and substantial insights for future research directions and challenges.},
  eventtitle = {{{IEEE Transactions}} on {{Artificial Intelligence}}},
  keywords = {Computer architecture,Convolutional neural network (CNN),embedded machine learning,Field programmable gate arrays,hardware accelerators,Pipelines,Reduced Instruction Set Computer (RISC-V),Reduced instruction set computing,Registers,Rockets,Surveys,transformers},
  file = {/home/wowaster/Zotero/storage/DDFSU3AG/Akkad et al. - 2024 - Embedded Deep Learning Accelerators A Survey on Recent Advances.pdf;/home/wowaster/Zotero/storage/SDSUXUWX/10239336.html}
}

@article{aspertiBolognaOptimalHigherorder1996,
  title = {The Bologna Optimal Higher-Order Machine},
  author = {Asperti, Andrea and Giovannetti, Cecilia and Naletto, Andrea},
  date = {1996-11},
  journaltitle = {Journal of Functional Programming},
  shortjournal = {J. Funct. Prog.},
  volume = {6},
  number = {6},
  pages = {763--810},
  issn = {0956-7968, 1469-7653},
  doi = {10.1017/S0956796800001994},
  url = {https://www.cambridge.org/core/product/identifier/S0956796800001994/type/journal_article},
  urldate = {2025-02-24},
  abstract = {The Bologna Optimal Higher-order Machine (BOHM) is a prototype implementation of the core of a functional language based on (a variant of) Lamping’s optimal graph reduction technique [Lam90, GAL92a, As94]. The source language is a sugared -calculus enriched with booleans, integers, lists and basic operations on these data types (following the guidelines of Interaction Systems [AL94, AL93b, Lan93]). In this paper, we shall describe BOHM’s general architecture (comprising the garbage collector), and we shall give a large set of benchmarks and experimental results.},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/6YJ5SDLX/Asperti et al. - 1996 - The bologna optimal higher-order machine.pdf}
}

@online{bestaGraphProcessingFPGAs2019,
  title = {Graph {{Processing}} on {{FPGAs}}: {{Taxonomy}}, {{Survey}}, {{Challenges}}},
  shorttitle = {Graph {{Processing}} on {{FPGAs}}},
  author = {Besta, Maciej and Stanojevic, Dimitri and Licht, Johannes De Fine and Ben-Nun, Tal and Hoefler, Torsten},
  date = {2019-04-27},
  eprint = {1903.06697},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1903.06697},
  url = {http://arxiv.org/abs/1903.06697},
  urldate = {2024-12-18},
  abstract = {Graph processing has become an important part of various areas, such as machine learning, computational sciences, medical applications, social network analysis, and many others. Various graphs, for example web or social networks, may contain up to trillions of edges. The sheer size of such datasets, combined with the irregular nature of graph processing, poses unique challenges for the runtime and the consumed power. Field Programmable Gate Arrays (FPGAs) can be an energy-efficient solution to deliver specialized hardware for graph processing. This is reflected by the recent interest in developing various graph algorithms and graph processing frameworks on FPGAs. To facilitate understanding of this emerging domain, we present the first survey and taxonomy on graph computations on FPGAs. Our survey describes and categorizes existing schemes and explains key ideas. Finally, we discuss research and engineering challenges to outline the future of graph computations on FPGAs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Hardware Architecture},
  file = {/home/wowaster/Zotero/storage/TKX87HN9/Besta et al. - 2019 - Graph Processing on FPGAs Taxonomy, Survey, Challenges.pdf;/home/wowaster/Zotero/storage/YAVV24I8/1903.html}
}

@article{chuiEconomicPotentialGenerative,
  title = {Economic Potential of Generative {{AI}}},
  author = {Chui, Michael and Hazan, Eric and Roberts, Roger and Singla, Alex and Smaje, Kate and Sukharevsky, Alex and Yee, Lareina and Zemmel, Rodney},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/PDPGQU8U/Chui et al. - The next productivity frontier.pdf;/home/wowaster/Zotero/storage/MKT3ALKQ/the-economic-potential-of-generative-ai-the-next-productivity-frontier.html}
}

@inproceedings{dakkakAcceleratingReductionScan2019,
  title = {Accelerating {{Reduction}} and {{Scan Using Tensor Core Units}}},
  booktitle = {Proceedings of the {{ACM International Conference}} on {{Supercomputing}}},
  author = {Dakkak, Abdul and Li, Cheng and Gelado, Isaac and Xiong, Jinjun and Hwu, Wen-mei},
  date = {2019-06-26},
  eprint = {1811.09736},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {46--57},
  doi = {10.1145/3330345.3331057},
  url = {http://arxiv.org/abs/1811.09736},
  urldate = {2025-02-22},
  abstract = {Driven by deep learning, there has been a surge of specialized processors for matrix multiplication, referred to as Tensor Core Units (TCUs). These TCUs are capable of performing matrix multiplications on small matrices (usually 4 × 4 or 16 × 16) to accelerate HPC and deep learning workloads. Although TCUs are prevalent and promise increase in performance and/or energy efficiency, they suffer from over specialization as only matrix multiplication on small matrices is supported. In this paper we express both reduction and scan in terms of matrix multiplication operations and map them onto TCUs. To our knowledge, this paper is the first to try to broaden the class of algorithms expressible as TCU operations and is the first to show benefits of this mapping in terms of: program simplicity, efficiency, and performance. We implemented the reduction and scan algorithms using NVIDIA’s V100 TCUs and achieved 89\% − 98\% of peak memory copy bandwidth. Our results are orders of magnitude faster (up to 100× for reduction and 3× for scan) than state-of-the-art methods for small segment sizes (common in HPC and deep learning applications). Our implementation achieves this speedup while decreasing the power consumption by up to 22\% for reduction and 16\% for scan.},
  langid = {english},
  keywords = {Computer Science - Performance},
  file = {/home/wowaster/Zotero/storage/2XQZF69R/Dakkak et al. - 2019 - Accelerating Reduction and Scan Using Tensor Core Units.pdf}
}

@inproceedings{duHighPerformanceSparseLinear2022,
  title = {High-{{Performance Sparse Linear Algebra}} on {{HBM-Equipped FPGAs Using HLS}}: {{A Case Study}} on {{SpMV}}},
  shorttitle = {High-{{Performance Sparse Linear Algebra}} on {{HBM-Equipped FPGAs Using HLS}}},
  booktitle = {Proceedings of the 2022 {{ACM}}/{{SIGDA International Symposium}} on {{Field-Programmable Gate Arrays}}},
  author = {Du, Yixiao and Hu, Yuwei and Zhou, Zhongchun and Zhang, Zhiru},
  date = {2022-02-13},
  pages = {54--64},
  publisher = {ACM},
  location = {Virtual Event USA},
  doi = {10.1145/3490422.3502368},
  url = {https://dl.acm.org/doi/10.1145/3490422.3502368},
  urldate = {2025-02-21},
  abstract = {Sparse linear algebra operators are memory bound due to low compute to memory access ratio and irregular data access patterns. The exceptional bandwidth improvement provided by the emerging high-bandwidth memory (HBM) technologies, coupled with the ability of FPGAs to customize the memory hierarchy and compute engines, brings the potential to significantly boost the performance of sparse linear algebra operators.},
  eventtitle = {{{FPGA}} '22: {{The}} 2022 {{ACM}}/{{SIGDA International Symposium}} on {{Field-Programmable Gate Arrays}}},
  isbn = {978-1-4503-9149-8},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/ZZK6FESU/Du et al. - 2022 - High-Performance Sparse Linear Algebra on HBM-Equipped FPGAs Using HLS A Case Study on SpMV.pdf}
}

@incollection{fernandezCalculusInteractionNets1999,
  title = {A {{Calculus}} for {{Interaction Nets}}},
  booktitle = {Principles and {{Practice}} of {{Declarative Programming}}},
  author = {Fernández, Maribel and Mackie, Ian},
  editor = {Nadathur, Gopalan},
  editora = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan},
  editoratype = {redactor},
  date = {1999},
  volume = {1702},
  pages = {170--187},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/10704567_10},
  url = {http://link.springer.com/10.1007/10704567_10},
  urldate = {2025-02-21},
  isbn = {978-3-540-66540-3 978-3-540-48164-5},
  file = {/home/wowaster/Zotero/storage/38Z2WCGH/Fernández and Mackie - 1999 - A Calculus for Interaction Nets.pdf}
}

@article{garciaPathQueryingGraph2024a,
  title = {Path {{Querying}} in {{Graph Databases}}: {{A Systematic Mapping Study}}},
  shorttitle = {Path {{Querying}} in {{Graph Databases}}},
  author = {García, Roberto and Angles, Renzo},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {33154--33172},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3371976},
  url = {https://ieeexplore.ieee.org/document/10456906},
  urldate = {2024-12-18},
  abstract = {Path querying refers to the evaluation of path queries in a graph database. New research in this topic is crucial for the development of graph database systems as path queries are associated with relevant use-cases and application domains. The aim of this article is to identify and establish what is currently known about path querying in graph databases. To achieve this, we conducted a systematic mapping study (SMS) in which we explored four digital libraries and collected research papers published from 1970 to 2022. These articles were filtered, classified and analyzed to extract quantitative and qualitative information which is presented in this article. Additionally, we provide a concise description of keywords, use-cases and application domains associated with path querying in graph databases.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Data models,Database languages,Databases,Graphical models,Optimization methods,Path,Path planning,path querying,Query processing,Reviews,Surveys,Systematics},
  file = {/home/wowaster/Zotero/storage/SKPH7359/García and Angles - 2024 - Path Querying in Graph Databases A Systematic Mapping Study.pdf;/home/wowaster/Zotero/storage/BQ7M9HCJ/10456906.html}
}

@inproceedings{gonthierGeometryOptimalLambda1992,
  title = {The Geometry of Optimal Lambda Reduction},
  booktitle = {Proceedings of the 19th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author = {Gonthier, Georges and Abadi, Martín and Lévy, Jean-Jacques},
  date = {1992-02-01},
  series = {{{POPL}} '92},
  pages = {15--26},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/143165.143172},
  url = {https://dl.acm.org/doi/10.1145/143165.143172},
  urldate = {2025-02-23},
  abstract = {Lamping discovered an optimal graph-reduction implementation of the λ-calculus. Simultaneously, Girard invented the geometry of interaction, a mathematical foundation for operational semantics. In this paper, we connect and explain the geometry of interaction and Lamping's graphs. The geometry of interaction provides a suitable semantic basis for explaining and improving Lamping's system. On the other hand, graphs similar to Lamping's provide a concrete representation of the geometry of interaction. Together, they offer a new understanding of computation, as well as ideas for efficient and correct implementations.},
  isbn = {978-0-89791-453-6},
  file = {/home/wowaster/Zotero/storage/SCWV8PYZ/Gonthier et al. - 1992 - The geometry of optimal lambda reduction.pdf}
}

@article{hindleyPrincipalTypeSchemeObject1969,
  title = {The {{Principal Type-Scheme}} of an {{Object}} in {{Combinatory Logic}}},
  author = {Hindley, R.},
  date = {1969},
  journaltitle = {Transactions of the American Mathematical Society},
  volume = {146},
  eprint = {1995158},
  eprinttype = {jstor},
  pages = {29--60},
  publisher = {American Mathematical Society},
  issn = {0002-9947},
  doi = {10.2307/1995158},
  url = {https://www.jstor.org/stable/1995158},
  urldate = {2024-12-17}
}

@article{isaac-chassandeDedicatedHardwareAccelerators2024,
  title = {Dedicated {{Hardware Accelerators}} for {{Processing}} of {{Sparse Matrices}} and {{Vectors}}: {{A Survey}}},
  shorttitle = {Dedicated {{Hardware Accelerators}} for {{Processing}} of {{Sparse Matrices}} and {{Vectors}}},
  author = {Isaac–Chassande, Valentin and Evans, Adrian and Durand, Yves and Rousseau, Frédéric},
  date = {2024-06-30},
  journaltitle = {ACM Transactions on Architecture and Code Optimization},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  volume = {21},
  number = {2},
  pages = {1--26},
  issn = {1544-3566, 1544-3973},
  doi = {10.1145/3640542},
  url = {https://dl.acm.org/doi/10.1145/3640542},
  urldate = {2025-02-21},
  abstract = {Performance in scientific and engineering applications such as computational physics, algebraic graph problems or Convolutional Neural Networks (CNN), is dominated by the manipulation of large sparse matrices—matrices with a large number of zero elements. Specialized software using data formats for sparse matrices has been optimized for the main kernels of interest: SpMV and SpMSpM matrix multiplications, but due to the indirect memory accesses, the performance is still limited by the memory hierarchy of conventional computers. Recent work shows that specific hardware accelerators can reduce memory traffic and improve the execution time of sparse matrix multiplication, compared to the best software implementations. The performance of these sparse hardware accelerators depends on the choice of the sparse format,               COO               ,               CSR               , etc, the algorithm,               inner-product               ,               outer-product               ,               Gustavson               , and many hardware design choices. In this article, we propose a systematic survey which identifies the design choices of state-of-the-art accelerators for sparse matrix multiplication kernels. We introduce the necessary concepts and then present, compare, and classify the main sparse accelerators in the literature, using consistent notations. Finally, we propose a taxonomy for these accelerators to help future designers make the best choices depending on their objectives.},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/NXFHV3T9/Isaac–Chassande et al. - 2024 - Dedicated Hardware Accelerators for Processing of Sparse Matrices and Vectors A Survey.pdf}
}

@inproceedings{jouppiInDatacenterPerformanceAnalysis2017,
  title = {In-{{Datacenter Performance Analysis}} of a {{Tensor Processing Unit}}},
  booktitle = {Proceedings of the 44th {{Annual International Symposium}} on {{Computer Architecture}}},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
  date = {2017-06-24},
  series = {{{ISCA}} '17},
  pages = {1--12},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3079856.3080246},
  url = {https://dl.acm.org/doi/10.1145/3079856.3080246},
  urldate = {2025-02-21},
  abstract = {Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95\% of our datacenters' NN inference demand. Despite low utilization for some applications, the TPU is on average about 15X -- 30X faster than its contemporary GPU or CPU, with TOPS/Watt about 30X -- 80X higher. Moreover, using the CPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.},
  isbn = {978-1-4503-4892-8},
  file = {/home/wowaster/Zotero/storage/BQ8RJR6J/Jouppi et al. - 2017 - In-Datacenter Performance Analysis of a Tensor Processing Unit.pdf}
}

@article{lafontInteractionCombinators1997,
  title = {Interaction {{Combinators}}},
  author = {Lafont, Yves},
  date = {1997-08-25},
  journaltitle = {Information and Computation},
  shortjournal = {Information and Computation},
  volume = {137},
  number = {1},
  pages = {69--101},
  issn = {0890-5401},
  doi = {10.1006/inco.1997.2643},
  url = {https://www.sciencedirect.com/science/article/pii/S0890540197926432},
  urldate = {2024-12-17},
  abstract = {It is shown that a very simple system ofinteraction combinators, with only three symbols and six rules, is a universal model of distributed computation, in a sense that will be made precise. This paper is the continuation of the author's work oninteraction nets, inspired by Girard's proof nets forlinear logic, but no preliminary knowledge of these topics is required for its reading.},
  file = {/home/wowaster/Zotero/storage/B3J9BIBL/Lafont - 1997 - Interaction Combinators.pdf;/home/wowaster/Zotero/storage/SC5KESQX/S0890540197926432.html}
}

@inproceedings{lafontInteractionNets1989,
  title = {Interaction Nets},
  booktitle = {Proceedings of the 17th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author = {Lafont, Yves},
  date = {1989-12-01},
  series = {{{POPL}} '90},
  pages = {95--108},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/96709.96718},
  url = {https://dl.acm.org/doi/10.1145/96709.96718},
  urldate = {2024-12-16},
  abstract = {We propose a new kind of programming language, with the following features:Interaction nets generalize Girard's proof nets of linear logic and illustrate the advantage of an integrated logic approach, as opposed to the external one. In other words, we did not try to design a logic describing the behaviour of some given computational system, but a programming language for which the type discipline is already (almost) a logic.In fact, we shall scarcely refer to logic, because we adopt a naïve and pragmatic style. A typical application we have in mind for this language is the design of interactive softwares such as editors or window managers.},
  isbn = {978-0-89791-343-0},
  file = {/home/wowaster/Zotero/storage/YE7QG8L6/Lafont - 1989 - Interaction nets.pdf}
}

@inproceedings{lampingAlgorithmOptimalLambda1990,
  title = {An Algorithm for Optimal Lambda Calculus Reduction},
  booktitle = {Proceedings of the 17th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages  - {{POPL}} '90},
  author = {Lamping, John},
  date = {1990},
  pages = {16--30},
  publisher = {ACM Press},
  location = {San Francisco, California, United States},
  doi = {10.1145/96709.96711},
  url = {http://portal.acm.org/citation.cfm?doid=96709.96711},
  urldate = {2025-02-24},
  eventtitle = {The 17th {{ACM SIGPLAN-SIGACT}} Symposium},
  isbn = {978-0-89791-343-0},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/NEKV8JFG/Lamping - 1990 - An algorithm for optimal lambda calculus reduction.pdf}
}

@incollection{mackieInteractionNetImplementation2011,
  title = {An {{Interaction Net Implementation}} of {{Closed Reduction}}},
  booktitle = {Implementation and {{Application}} of {{Functional Languages}}},
  author = {Mackie, Ian},
  editor = {Scholz, Sven-Bodo and Chitil, Olaf},
  date = {2011},
  volume = {5836},
  pages = {43--59},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-24452-0_3},
  url = {http://link.springer.com/10.1007/978-3-642-24452-0_3},
  urldate = {2025-02-22},
  isbn = {978-3-642-24451-3 978-3-642-24452-0},
  file = {/home/wowaster/Zotero/storage/756YKPAB/Mackie - 2011 - An Interaction Net Implementation of Closed Reduction.pdf}
}

@article{mackieParallelEvaluationInteraction2016,
  title = {Parallel {{Evaluation}} of {{Interaction Nets}}: {{Case Studies}} and {{Experiments}}},
  shorttitle = {Parallel {{Evaluation}} of {{Interaction Nets}}},
  author = {Mackie, Ian and Sato, Shinya},
  date = {2016-04-18},
  journaltitle = {Electronic Communications of the EASST},
  volume = {73},
  issn = {1863-2122},
  doi = {10.14279/tuj.eceasst.73.1034},
  url = {https://eceasst.org/index.php/eceasst/article/view/2205},
  urldate = {2024-12-17},
  abstract = {Interaction nets are a particular kind of graph rewriting system that have many properties that make them useful for capturing sharing and parallelism. There have been a number of research efforts towards implementing interaction nets in parallel, and these have focused on the implementation technologies. In this paper we investigate a related question: when is an interaction net system suitable for parallel evaluation? We observe that some nets cannot benefit from parallelism (they are sequential) and some have the potential to be evaluated in a highly parallel way. This first investigation aims to highlight a number of issues, by presenting experimental evidence for a number of case studies. We hope this can be used to help pave the way to a wider use of this technology for parallel evaluation.},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/T67JDU5P/Mackie and Sato - 2016 - Parallel Evaluation of Interaction Nets Case Studies and Experiments.pdf}
}

@article{milnerTheoryTypePolymorphism1978,
  title = {A Theory of Type Polymorphism in Programming},
  author = {Milner, Robin},
  date = {1978-12-01},
  journaltitle = {Journal of Computer and System Sciences},
  shortjournal = {Journal of Computer and System Sciences},
  volume = {17},
  number = {3},
  pages = {348--375},
  issn = {0022-0000},
  doi = {10.1016/0022-0000(78)90014-4},
  url = {https://www.sciencedirect.com/science/article/pii/0022000078900144},
  urldate = {2024-12-17},
  abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.},
  file = {/home/wowaster/Zotero/storage/EABBQE7S/Milner - 1978 - A theory of type polymorphism in programming.pdf;/home/wowaster/Zotero/storage/AECP7PY2/0022000078900144.html}
}

@online{mohammedPerformanceEnhancementStrategies2022,
  title = {Performance {{Enhancement Strategies}} for {{Sparse Matrix-Vector Multiplication}} ({{SpMV}}) and {{Iterative Linear Solvers}}},
  author = {Mohammed, Thaha and Mehmood, Rashid},
  date = {2022-12-14},
  eprint = {2212.07490},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.07490},
  url = {http://arxiv.org/abs/2212.07490},
  urldate = {2025-02-21},
  abstract = {Iterative solutions of sparse linear systems and sparse eigenvalue problems have a fundamental role in vital fields of scientific research and engineering. The crucial computing kernel for such iterative solutions is the multiplication of a sparse matrix by a dense vector. Efficient implementation of sparse matrix-vector multiplication (SpMV) and linear solvers are therefore essential and has been subjected to extensive research across a variety of computing architectures and accelerators such as central processing units (CPUs), graphical processing units (GPUs), many integrated cores (MICs), and field programmable gate arrays (FPGAs). Unleashing the full potential of an architecture/accelerator requires determining the factors that affect an efficient implementation of SpMV. This article presents the first of its kind, in-depth survey covering over two hundred state-of-the-art optimization schemes for solving sparse iterative linear systems with a focus on computing SpMV. A new taxonomy for iterative solutions and SpMV techniques common to all architectures is proposed. This article includes reviews of SpMV techniques for all architectures to consolidate a single taxonomy to encourage cross-architectural and heterogeneous-architecture developments. However, the primary focus is on GPUs. The major contributions as well as the primary, secondary, and tertiary contributions of the SpMV techniques are first highlighted utilizing the taxonomy and then qualitatively compared. A summary of the current state of the research for each architecture is discussed separately. Finally, several open problems and key challenges for future research directions are outlined.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Numerical Analysis,Mathematics - Numerical Analysis},
  file = {/home/wowaster/Zotero/storage/YMXC5R22/Mohammed and Mehmood - 2022 - Performance Enhancement Strategies for Sparse Matrix-Vector Multiplication (SpMV) and Iterative Line.pdf}
}

@book{peytonjones1987the,
  title = {The Implementation of Functional Programming Languages},
  author = {Peyton Jones, Simon L.},
  date = {1987-04},
  publisher = {Prentice Hall Internaltional (UK) Ltd.},
  url = {https://www.microsoft.com/en-us/research/publication/the-implementation-of-functional-programming-languages-2/},
  abstract = {“The Implementation of Functional Languages” is a book about implementing functional programming languages using lazy graph reduction, and it divides into three parts. The first part describes how to translate a high-level functional language into an intermediate language, called the lambda calculus, incuding detailed coverage of pattern-matching and type-checking. The second part begins with a simple implementation of the lambda calculus, based on graph reduction, and then develops a number of refinements and alternatives. The third part describes the G-machine, a sophisticated implementation of graph reduction, which provides a dramatic increase in performance over the implementations described earlier.},
  file = {/home/wowaster/Zotero/storage/Q232JGMW/Peyton Jones - 1987 - The implementation of functional programming langu.pdf}
}

@inproceedings{reynoldsDefinitionalInterpretersHigherorder1972,
  title = {Definitional Interpreters for Higher-Order Programming Languages},
  booktitle = {Proceedings of the {{ACM}} Annual Conference on   - {{ACM}} '72},
  author = {Reynolds, John C.},
  date = {1972},
  volume = {2},
  pages = {717--740},
  publisher = {ACM Press},
  location = {Boston, Massachusetts, United States},
  doi = {10.1145/800194.805852},
  url = {http://portal.acm.org/citation.cfm?doid=800194.805852},
  urldate = {2025-03-04},
  abstract = {Higher-order programming languages (i.e., languages in which procedures or labels can occur as values) are usually defined by interpreters that are themselves written in a programming language based on the lambda calculus (i.e., an applicative language such as pure LISP). Examples include McCarthy’s definition of LISP, Landin’s SECD machine, the Vienna definition of PL/I, Reynolds’ definitions of GEDANKEN, and recent unpublished work by L. Morris and C. Wadsworth. Such definitions can be classified according to whether the interpreter contains higher-order functions, and whether the order of application (i.e., call by value versus call by name) in the defined language depends upon the order of application in the defining language. As an example, we consider the definition of a simple applicative programming language by means of an interpreter written in a similar language. Definitions in each of the above classifications are derived from one another by informal but constructive methods. The treatment of imperative features such as jumps and assignment is also discussed.},
  eventtitle = {The {{ACM}} Annual Conference},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/QNFVSMJY/Reynolds - 1972 - Definitional interpreters for higher-order programming languages.pdf}
}

@online{salikhmetovInteractionNetsRussian2013,
  title = {Interaction {{Nets}} in {{Russian}}},
  author = {Salikhmetov, Anton},
  date = {2013-04-05},
  eprint = {1304.1309},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1304.1309},
  url = {http://arxiv.org/abs/1304.1309},
  urldate = {2024-12-17},
  abstract = {Draft translation to Russian of Chapter 7, Interaction-Based Models of Computation, from Models of Computation: An Introduction to Computability Theory by Maribel Fernandez. "In this chapter, we study interaction nets, a model of computation that can be seen as a representative of a class of models based on the notion of 'computation as interaction'. Interaction nets are a graphical model of computation devised by Yves Lafont in 1990 as a generalisation of the proof structures of linear logic. It can be seen as an abstract formalism, used to define algorithms and analyse their cost, or as a low-level language into which other programming languages can be compiled. This is fruitful because interaction nets can be implemented with reasonable efficiency."},
  pubstate = {prepublished},
  keywords = {Computer Science - Formal Languages and Automata Theory,Computer Science - Logic in Computer Science},
  file = {/home/wowaster/Zotero/storage/PZ8KNKIC/Salikhmetov - 2013 - Interaction Nets in Russian.pdf;/home/wowaster/Zotero/storage/EXM9H36C/1304.html}
}

@article{salikhmetovTokenpassingOptimalReduction2016a,
  title = {Token-Passing {{Optimal Reduction}} with {{Embedded Read-back}}},
  author = {Salikhmetov, Anton},
  date = {2016-09-10},
  journaltitle = {Electronic Proceedings in Theoretical Computer Science},
  shortjournal = {Electron. Proc. Theor. Comput. Sci.},
  volume = {225},
  eprint = {1609.03644},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {45--54},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.225.7},
  url = {http://arxiv.org/abs/1609.03644},
  urldate = {2024-12-17},
  abstract = {We introduce a new interaction net implementation of optimal reduction for the pure untyped lambda calculus. Unlike others, our implementation allows to reach normal form regardless of the interaction net reduction strategy using the approach of so-called token-passing nets and a non-deterministic extension for interaction nets. Another new feature is the read-back mechanism implemented without leaving the formalism of interaction nets.},
  keywords = {Computer Science - Logic in Computer Science},
  file = {/home/wowaster/Zotero/storage/X85U6X57/Salikhmetov - 2016 - Token-passing Optimal Reduction with Embedded Read-back.pdf;/home/wowaster/Zotero/storage/BG5KHIZZ/1609.html}
}

@thesis{satoDesignImplementationLowlevel2015,
  type = {thesis},
  title = {Design and Implementation of a Low-Level Language for Interaction Nets},
  author = {Sato, Shinya},
  date = {2015-05-18},
  institution = {University of Sussex},
  url = {https://sussex.figshare.com/articles/thesis/Design_and_implementation_of_a_low-level_language_for_interaction_nets/23417312/1},
  urldate = {2025-02-14},
  abstract = {Interaction nets are a graphical model of computation based on a restricted form of graph rewriting. A specific net can represent a program with a user-defined set of nodes and computation is modelled by a user-defined set of rewrite rules. This very simple model has had great success in modelling sharing in computation (specifically in the lambda calculus), and there is potential for generating a new theoretical foundation of parallel computation since all computation steps are local and thus can be implemented in parallel. This thesis is about the implementation of interaction nets. Specifically, for the first contributions we define a low-level language as an object language for the compilation of interaction nets. We study the efficiency and properties of different data structures, and focus on the management of the rewriting process which is usually hidden in the graph rewriting system. We provide experimental data comparing the different choices of data structures and select one for further development. For the compilation of nets and rules into this language, we show an optimisation such that allocated memory for agents is reused, and thus we obtain optimal efficiency for the rewriting process. The second part of this thesis describes extensions of interaction nets so that they can be used as a programming language. Interaction nets in their pure form are quite restrictive in expressive power. By extending the notions of agents and rules we can express computation more naturally, yet still preserve the good properties (such as strong confluence) of the rewriting system. We then implement a selection of algorithms using and extending the compilation techniques developed in the first part of the thesis. We also demonstrate experimental results on multi-core CPUs, using the Posix-thread library, thus realising some of the potential for parallel implementation mentioned above.},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/UVWVA5EW/Sato - 2015 - Design and implementation of a low-level language for interaction nets.pdf}
}

@article{schrijversTypeCheckingOpen2008,
  title = {Type {{Checking}} with {{Open Type Functions}}},
  author = {Schrijvers, Tom and Jones, Simon Peyton and Chakravarty, Manuel and Sulzmann, Martin},
  date = {2008-09-22},
  journaltitle = {ResearchGate},
  doi = {10.1145/1411204.1411215},
  url = {https://www.researchgate.net/publication/221241290_Type_checking_with_open_type_functions},
  abstract = {We report on an extension of Haskell with open type-level functions and equality constraints that unifies earlier work on GADTs, functional dependencies, and associated types. The contribution of the paper is that we identify and characterise the key technical challenge of entailment checking; and we give a novel, decidable, sound, and complete algorithm to solve it, together with some practically-important variants. Our system is implemented in GHC, and is already in active use.},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/L9ZZ4N6M/2024 - (PDF) Type checking with open type functions.pdf;/home/wowaster/Zotero/storage/F5FGGLVS/221241290_Type_checking_with_open_type_functions.html}
}

@online{shayannajdTreesThatGrow,
  title = {Trees That {{Grow}}},
  author = {{Shayan Najd} and {Simon Peyton Jones}},
  eprinttype = {Verlag der Technischen Universität Graz},
  doi = {10.3217/JUCS-023-01-0042},
  url = {https://lib.jucs.org/article/22912},
  urldate = {2024-12-17},
  pubstate = {prepublished},
  file = {/home/wowaster/Zotero/storage/DMN988VZ/Shayan Najd and Simon Peyton Jones - Trees that Grow.pdf}
}

@online{silvanoSurveyDeepLearning2024,
  title = {A {{Survey}} on {{Deep Learning Hardware Accelerators}} for {{Heterogeneous HPC Platforms}}},
  author = {Silvano, Cristina and Ielmini, Daniele and Ferrandi, Fabrizio and Fiorin, Leandro and Curzel, Serena and Benini, Luca and Conti, Francesco and Garofalo, Angelo and Zambelli, Cristian and Calore, Enrico and Schifano, Sebastiano Fabio and Palesi, Maurizio and Ascia, Giuseppe and Patti, Davide and Petra, Nicola and Caro, Davide De and Lavagno, Luciano and Urso, Teodoro and Cardellini, Valeria and Cardarilli, Gian Carlo and Birke, Robert and Perri, Stefania},
  date = {2024-07-12},
  eprint = {2306.15552},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.15552},
  url = {http://arxiv.org/abs/2306.15552},
  urldate = {2025-02-22},
  abstract = {CCS Concepts: • Computer systems organization → Architectures; • Hardware → Reconfigurable logic and FPGAs; Emerging technologies; Very large scale integration design; Power and energy; • Computing methodologies → Machine learning.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Emerging Technologies,Computer Science - Hardware Architecture,Computer Science - Machine Learning},
  file = {/home/wowaster/Zotero/storage/WGF7MYCP/Silvano et al. - 2024 - A Survey on Deep Learning Hardware Accelerators for Heterogeneous HPC Platforms.pdf}
}

@incollection{sinotCallbyNameCallbyValueTokenPassing2005,
  title = {Call-by-{{Name}} and {{Call-by-Value}} as {{Token-Passing Interaction Nets}}},
  booktitle = {Typed {{Lambda Calculi}} and {{Applications}}},
  author = {Sinot, François-Régis},
  editor = {Urzyczyn, Paweł},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2005},
  volume = {3461},
  pages = {386--400},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11417170_28},
  url = {http://link.springer.com/10.1007/11417170_28},
  urldate = {2025-02-24},
  abstract = {Two common misbeliefs about encodings of the λ-calculus in interaction nets (INs) are that they are good only for strategies that are not very well understood (e.g. optimal reduction) and that they always have to deal in a complex way with boxes. In brief, the theory of interaction nets is more or less disconnected from the standard theory: we can do things in INs that we cannot do with terms, which is true [5, 10]; and we cannot do in INs things that can easily be done with terms. This paper contributes to fighting this misbelief by showing that the standard call-by-name and call-by-value strategies of the λ-calculus are encoded in interaction nets in a very simple and extensible way, and in particular that these encodings do not need any notion of box. This work can also be seen as a first step towards a generic approach to derive graph-based abstract machines.},
  isbn = {978-3-540-25593-2 978-3-540-32014-2},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/EB3WTVFJ/Sinot - 2005 - Call-by-Name and Call-by-Value as Token-Passing Interaction Nets.pdf}
}

@article{sinotTokenPassingNetsCallbyNeed2006,
  title = {Token-{{Passing Nets}}: {{Call-by-Need}} for {{Free}}},
  shorttitle = {Token-{{Passing Nets}}},
  author = {Sinot, François-Régis},
  date = {2006-03-03},
  journaltitle = {Electronic Notes in Theoretical Computer Science},
  shortjournal = {Electronic Notes in Theoretical Computer Science},
  series = {Proceedings of the {{First International Workshop}} on {{Developments}} in {{Computational Models}} ({{DCM}} 2005)},
  volume = {135},
  number = {3},
  pages = {129--139},
  issn = {1571-0661},
  doi = {10.1016/j.entcs.2005.09.027},
  url = {https://www.sciencedirect.com/science/article/pii/S1571066106000934},
  urldate = {2025-02-22},
  abstract = {Recently, encodings in interaction nets of the call-by-name and call-by-value strategies of the λ-calculus have been proposed. The purpose of these encodings was to bridge the gap between interaction nets and traditional abstract machines, which are both used to provide lower-level specifications of strategies of the λ-calculus, but in radically different ways. The strength of these encodings is their simplicity, which comes from the simple idea of introducing an explicit syntactic object to represent the flow of evaluation. In particular, no artifact to represent boxes is needed. However, these encodings purposefully follow as closely as possible the implemented strategies, call-by-name and call-by-value, hence do not benefit from the ability of interaction nets to easily represent sharing. The aim of this note is to show that sharing can indeed be achieved without adding any structure. We thus present the call-by-need strategy following the same philosophy, which is indeed not any more complicated than call-by-name. This continues the task of bridging the gap between interaction nets and abstract machines, thus pushing forward a more uniform framework for implementations of the λ-calculus.},
  keywords = {-calculus,call-by-name,call-by-value,interaction net},
  file = {/home/wowaster/Zotero/storage/LTEN3DUM/Sinot - 2006 - Token-Passing Nets Call-by-Need for Free.pdf;/home/wowaster/Zotero/storage/A7J3MZJP/S1571066106000934.html}
}

@article{vincentvanoostromLambdascopeAnotherOptimal2004,
  title = {Lambdascope {{Another}} Optimal Implementation of the Lambda-Calculus},
  author = {{Vincent van Oostrom} and {Kees-Jan van de Looij} and {Marijn Zwitserlood}},
  date = {2004-05-04},
  langid = {english},
  file = {/home/wowaster/Zotero/storage/N9YLN9DZ/van Oostrom et al. - Lambdascope Another optimal implementation of the lambda-calculus.pdf}
}

@online{zhuMobileMachineLearning2018,
  title = {Mobile {{Machine Learning Hardware}} at {{ARM}}: {{A Systems-on-Chip}} ({{SoC}}) {{Perspective}}},
  shorttitle = {Mobile {{Machine Learning Hardware}} at {{ARM}}},
  author = {Zhu, Yuhao and Mattina, Matthew and Whatmough, Paul},
  date = {2018-02-01},
  eprint = {1801.06274},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1801.06274},
  url = {http://arxiv.org/abs/1801.06274},
  urldate = {2025-02-22},
  abstract = {Machine learning is playing an increasingly significant role in emerging mobile application domains such as AR/VR, ADAS, etc. Accordingly, hardware architects have designed customized hardware for machine learning algorithms, especially neural networks, to improve compute efficiency. However, machine learning is typically just one processing stage in complex end-to-end applications, involving multiple components in a mobile Systems-on-achip (SoC). Focusing only on ML accelerators loses bigger optimization opportunity at the system (SoC) level. This paper argues that hardware architects should expand the optimization scope to the entire SoC. We demonstrate one particular case-study in the domain of continuous computer vision where camera sensor, image signal processor (ISP), memory, and NN accelerator are synergistically co-designed to achieve optimal system-level efficiency.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/wowaster/Zotero/storage/93BCQJAT/Zhu et al. - 2018 - Mobile Machine Learning Hardware at ARM A Systems-on-Chip (SoC) Perspective.pdf}
}
