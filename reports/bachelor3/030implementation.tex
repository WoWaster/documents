% !TeX spellcheck = ru_RU
% !TEX root = vkr.tex

В качестве базовой реализации была выбрана реализация из ядра Linux\footnote{\url{https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/x86/crypto/crc32-pclmul_asm.S}}.
Она использует инструкцию PCLMULQDQ из набора команд CLMUL для архитектуры x86.
PCLMULQDQ оперирует на 128 битных регистрах XMM и обрабатывает 512 бит данных за раз.
Особенностью этой инструкции является то, что на вход она принимает два 64-битных числа из XMM регистров, а результат является 128-битным числом и занимает целый регистр

На \riscv{} доступны только регистры размера 64, поэтому существуют две инструкции: clmul и clmulh.
Обе принимают на вход 64-битные числа, но первая возвращает младшие 64 бита результата, а вторая, соответственно, старшие.

Разработка велась на языке ассемблера, поэтому набор доступных регистров был ограничен.
В силу этого ограничения, данная реализация обрабатывает только 128 бит за раз.

Длина входных данных должна быть кратна 128 битам.
Для решения этой проблемы используется функция-обертка, которая выравнивает данные, вычисляя \crctt{} по стандартному алгоритму до границы кратной 128 битам.

В процессе адаптации код, одной из самых сложных задач было правильно использование регистров.
В базовой реализации, из-за описанных выше особенностей инструкции PCLMULQDQ, значение регистра обязательно копируется в другой.
Этого хотелось избежать, т.к. количество гарантированно свободных регистров ограниченно.
В этом помогала остановка программы с помощью дебаггера и просмотр значения регистров.
\begin{lstlisting}[caption=Оригинальный код,
    label=lst:intel_clmul_orig,
    frame=single,
    mathescape=false]
movdqa  %xmm1, %xmm5
pclmulqdq $0x00, CONSTANT, %xmm1
pclmulqdq $0x11, CONSTANT, %xmm5
pxor    %xmm5, %xmm1
pxor    (BUF), %xmm1
\end{lstlisting}
Путем изучения содержимого регистров, удалось изменить данный код, используя меньше копирований.
\begin{lstlisting}[caption=Адаптированный код,
    label=lst:riscv_clmul_opt,
    frame=single,
    mathescape=false]
clmulh t3, CONSTANT_2, t1 # xmm5[127:64]
clmul t2, CONSTANT_2, t1 # xmm5[63:0]
clmulh t1, CONSTANT_1, t0 # xmm1[127:64]
clmul t0, CONSTANT_1, t0 # xmm1[63:0] 
xor t0, t0, t2 # xmm1[63:0] 
xor t1, t1, t3 # xmm1[127:64]
ld t4, 0(BUF)
xor t0, t0, t4
ld t4, 8(BUF)
xor t1, t1, t4
\end{lstlisting}
Тем не менее объем кода в этом месте увеличился вдвое, т.к. за раз можно обработать только 64 бита данных, а не 128.

Так же анализ регистров позволил оптимизировать операцию побитового сдвига.
Без оптимизации, для сдвига двух 64-битных регистров, которые рассматриваются как один 128-битный, на 32 бита вправо необходимо четыре инструкции.
\begin{lstlisting}[caption=Универсальный сдвиг на 32 вправо,
    frame=single,
    mathescape=false,
    keepspaces=true ]
srli t0, t0, 32 % Сдвинуть младшие биты на 32 вправо
slli t3, t1, 32 % Биты, которые необходимо 
                % перенести в другой регистр
or t0, t0, t3 % Объединить биты в один регистр
srli t1, t1, 32 % Сдвинуть старшие биты на 32 вправо
\end{lstlisting}
Оказалось, что в момент выполнения данной операции старшие 32 бита являются нулями и последняя инструкция не нужна.
